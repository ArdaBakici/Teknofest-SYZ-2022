{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import dicom2jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \".\\\\inputjpg\\\\\"\n",
    "#input_folder = \"X:\\\\FTP\\\\VeriSeti\\\\Training\\\\\"\n",
    "#input_folder = \"X:\\\\FTP\\\\v2\\\\To_Archive\\\\Archive_SYZ\\\\SYZJPG\\\\\"\n",
    "output_folder = \"./output/\"\n",
    "excel_loc = \"./BasBit.xlsx\"\n",
    "file_stack_save_path = output_folder + \"file_stack.json\"\n",
    "results_save_path = output_folder+ \"results.txt\"\n",
    "excel_save_path = output_folder + \"results.xlsx\"\n",
    "\n",
    "bb_cls_num_mapper = {\n",
    "    'Akut apandisit ile uyumlu': 1,\n",
    "    'Apandiks': 1,\n",
    "\n",
    "    'Akut kolesistit ile uyumlu': 2,\n",
    "    'Safra Kesesi': 2,\n",
    "\n",
    "    'Akut pankreatit ile uyumlu': 3,\n",
    "    'Pankreas': 3,\n",
    "\n",
    "    'Böbrek-Mesane': 4,\n",
    "    'Böbrek taşı': 4,\n",
    "    'Üreter taşı': 4,\n",
    "\n",
    "    'Akut divertikülit ile uyumlu': 5,\n",
    "    'Kolon': 5,\n",
    "\n",
    "    'Abdominal aort anevrizma': 6,\n",
    "    'Abdominal Aorta': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(files_map, read_dicom = False):\n",
    "    from detect1 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map\n",
    "\n",
    "def predict2(files_map, read_dicom = False):\n",
    "    from detect2 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map\n",
    "\n",
    "def predict3(files_map, read_dicom = False):\n",
    "    from detect3 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map\n",
    "\n",
    "def predict4(files_map, read_dicom = False):\n",
    "    from detect4 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map\n",
    "\n",
    "def predict5(files_map, read_dicom = False):\n",
    "    from detect5 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map\n",
    "\n",
    "def predict6(files_map, read_dicom = False):\n",
    "    from detect6 import analyze\n",
    "    res_map = {}\n",
    "    for patient in tqdm(files_map):\n",
    "        if res_map.get(patient) is None:\n",
    "            res_map[patient] = {}\n",
    "\n",
    "        for serie in files_map[patient]:\n",
    "            if res_map[patient].get(serie) is None:\n",
    "                res_map[patient][serie] = {}\n",
    "\n",
    "            for image in files_map[patient][serie]:\n",
    "                if read_dicom:\n",
    "                    n_img = dicom2jpg.dicom2img(image)\n",
    "                    n_img = cv2.cvtColor(n_img, cv2.COLOR_GRAY2BGR)\n",
    "                    results = analyze(n_img, color_transpose=True)\n",
    "                else: \n",
    "                    results = analyze(cv2.imread(image), color_transpose=True)\n",
    "                res_map[patient][serie][image.split('\\\\')[-1].split('.')[0]] = results\n",
    "\n",
    "    return res_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT USE\n",
    "\n",
    "def convert_excel_to_json(excel, patients_map):\n",
    "    files_stack = {}\n",
    "\n",
    "    for index, row in tqdm(excel.iterrows(), total=len(excel)):\n",
    "        patient, series = row['Olgu Numarası'].rsplit(\"/\", 1)\n",
    "        image_name = row['Kesit Numarası']\n",
    "        if row[\"Tip\"] == 'BB':\n",
    "            continue\n",
    "\n",
    "        images_map = patients_map[patient][series]\n",
    "        \n",
    "        try:\n",
    "            cls_num = bb_cls_num_mapper[row[\"Sınıf\"]]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if files_stack.get(cls_num) is None:\n",
    "            files_stack[cls_num] = {}\n",
    "        if files_stack[cls_num].get(patient) is None:\n",
    "            files_stack[cls_num][patient] = {}\n",
    "        if files_stack[cls_num][patient].get(series) is None:\n",
    "            files_stack[cls_num][patient][series] = []\n",
    "\n",
    "        files_stack[cls_num][patient][series].append(images_map[str(image_name)])\n",
    "\n",
    "    with open(file_stack_save_path, \"w\") as file:\n",
    "        json.dump(files_stack, file)\n",
    "\n",
    "    return files_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicies_convert_excel_to_json(excel, patients_map):\n",
    "    files_stack = {}\n",
    "    organ_stack = {}\n",
    "    existed = False\n",
    "    prev_img = None\n",
    "    for index, row in tqdm(excel.iterrows(), total=len(excel)):\n",
    "        patient, series = row['Olgu Numarası'].rsplit(\"\\\\\", 1)\n",
    "        #patient, series = row['Olgu Numarası'].rsplit(\"/\", 1)\n",
    "        image_name = row['Kesit Numarası']\n",
    "        if patient!=prev_img:\n",
    "            if len(organ_stack.keys()) != 0:\n",
    "                print(\"Single Label\")\n",
    "                print(organ_stack.keys())\n",
    "                print(image_name)\n",
    "        if row[\"Tip\"] == 'BB':\n",
    "            continue\n",
    "        \n",
    "        #if patient == \"16492\":\n",
    "        #   continue\n",
    "            \n",
    "        images_map = patients_map[patient][series]\n",
    "        \n",
    "        try:\n",
    "            cls_num = bb_cls_num_mapper[row[\"Sınıf\"]]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if files_stack.get(cls_num) is None:\n",
    "            files_stack[cls_num] = {}\n",
    "        if files_stack[cls_num].get(patient) is None:\n",
    "            files_stack[cls_num][patient] = {}\n",
    "        if files_stack[cls_num][patient].get(series) is None:\n",
    "            files_stack[cls_num][patient][series] = []\n",
    "    \n",
    "        #if row[\"Tip\"] == \"Başlangıç/Bitiş Kesiti\":\n",
    "        stack = organ_stack.pop(row[\"Sınıf\"], None)\n",
    "        if stack == None:\n",
    "            organ_stack[row[\"Sınıf\"]] = row['Kesit Numarası']\n",
    "        else:\n",
    "            for key in images_map:\n",
    "                if int(key) >= stack and int(key) <= row['Kesit Numarası']:\n",
    "                    files_stack[cls_num][patient][series].append(images_map[key])\n",
    "        prev_img = patient\n",
    "\n",
    "    with open(file_stack_save_path, \"w\") as file:\n",
    "        json.dump(files_stack, file)\n",
    "\n",
    "    return files_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:00<00:00, 334.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# read excel and create class based file dictonary\n",
    "excel = pd.read_excel(excel_loc)\n",
    "images_dict = {}\n",
    "patient_folders = glob(input_folder + '*\\\\')\n",
    "\n",
    "for folder in tqdm(patient_folders):\n",
    "    patient_name = folder.split('\\\\')[-2]\n",
    "    if images_dict.get(patient_name) is None:\n",
    "            images_dict[patient_name] = {}\n",
    "    series = glob(folder + '*\\\\')\n",
    "    for serie in series:\n",
    "        series_name = serie.split('\\\\')[-2]\n",
    "        if images_dict[patient_name].get(series_name) is None:\n",
    "            images_dict[patient_name][series_name] = {}\n",
    "        images = glob(serie + '*')\n",
    "        for image in images:\n",
    "            images_dict[patient_name][series_name][image.split('\\\\')[-1].rsplit(\".\", 1)[0]] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:00<00:00, 16239.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#files_dict = convert_excel_to_json(excel, images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1246/1246 [00:00<00:00, 1432.02it/s]\n"
     ]
    }
   ],
   "source": [
    "files_dict = indicies_convert_excel_to_json(excel, images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "Using CUDA device0 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1660 Ti with Max-Q Design', total_memory=6143MB)\n",
      "\n",
      "Fusing layers... Model Summary: 417 layers, 1.26639e+08 parameters, 1.23263e+08 gradients\n",
      "Debug: Analyzing with Apandisit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/103 [00:49<13:16,  8.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mx:\\Arşiv\\Coding\\SYZ\\manager.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m files_dict\u001b[39m.\u001b[39mget(\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     results_dict[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m predict1(files_dict[\u001b[39m1\u001b[39;49m], read_dicom)\n\u001b[0;32m      <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPhase 1 DONE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m files_dict\u001b[39m.\u001b[39mget(\u001b[39m2\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32mx:\\Arşiv\\Coding\\SYZ\\manager.ipynb Cell 9\u001b[0m in \u001b[0;36mpredict1\u001b[1;34m(files_map, read_dicom)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 results \u001b[39m=\u001b[39m analyze(n_img, color_transpose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             \u001b[39melse\u001b[39;00m: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                 results \u001b[39m=\u001b[39m analyze(cv2\u001b[39m.\u001b[39;49mimread(image), color_transpose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             res_map[patient][serie][image\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m results\n\u001b[0;32m     <a href='vscode-notebook-cell:/x%3A/Ar%C5%9Fiv/Coding/SYZ/manager.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res_map\n",
      "File \u001b[1;32mx:\\Arşiv\\Coding\\SYZ\\detect1.py:63\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(img0, save_loc, _augment, conf_thres, iou_thres, agnostic_nms, color_transpose)\u001b[0m\n\u001b[0;32m     61\u001b[0m pred \u001b[39m=\u001b[39m model(img, augment\u001b[39m=\u001b[39m_augment)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     62\u001b[0m \u001b[39m# Apply NMS\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m pred \u001b[39m=\u001b[39m non_max_suppression(pred, conf_thres, iou_thres, agnostic\u001b[39m=\u001b[39;49magnostic_nms)\n\u001b[0;32m     64\u001b[0m \u001b[39m#t2 = time_synchronized()\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m# Process detections\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m i, det \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pred):  \u001b[39m# detections per image\u001b[39;00m\n",
      "File \u001b[1;32mx:\\Arşiv\\Coding\\SYZ\\utils\\general.py:588\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, merge, classes, agnostic)\u001b[0m\n\u001b[0;32m    584\u001b[0m output \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m prediction\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    585\u001b[0m \u001b[39mfor\u001b[39;00m xi, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(prediction):  \u001b[39m# image index, image inference\u001b[39;00m\n\u001b[0;32m    586\u001b[0m     \u001b[39m# Apply constraints\u001b[39;00m\n\u001b[0;32m    587\u001b[0m     \u001b[39m# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m     x \u001b[39m=\u001b[39m x[xc[xi]]  \u001b[39m# confidence\u001b[39;00m\n\u001b[0;32m    590\u001b[0m     \u001b[39m# If none remain process next image\u001b[39;00m\n\u001b[0;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# predict\n",
    "read_dicom = False\n",
    "results_dict = {}\n",
    "if files_dict.get(1) != None:\n",
    "    print(\"Started\")\n",
    "    results_dict[1] = predict1(files_dict[1], read_dicom)\n",
    "print(\"Phase 1 DONE\")\n",
    "if files_dict.get(2) != None:\n",
    "    results_dict[2] = predict2(files_dict[2], read_dicom)\n",
    "print(\"Phase 2 DONE\")\n",
    "if files_dict.get(3) != None:\n",
    "    results_dict[3] = predict3(files_dict[3], read_dicom)\n",
    "print(\"Phase 3 DONE\")\n",
    "if files_dict.get(6) != None:\n",
    "    results_dict[6] = predict6(files_dict[6], read_dicom)\n",
    "print(\"Phase 6 DONE\")\n",
    "if files_dict.get(5) != None:\n",
    "    results_dict[5] = predict5(files_dict[5], read_dicom)\n",
    "print(\"Phase 5 DONE\")\n",
    "if files_dict.get(4) != None:\n",
    "    results_dict[4] = predict4(files_dict[4], read_dicom)\n",
    "print(\"Phase 4 DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Olgu Numarası Kesit Numarası Tip  Sınıf             Veri\n",
      "0      1187982/Seri3    30217929805  BB      3  253,185-307,228\n",
      "1      1187982/Seri3    30217929805  BB      3  292,219-378,297\n",
      "2      1187982/Seri3    30217929805  BB      5  255,188-286,225\n",
      "3      1187982/Seri3    30217929806  BB      3  249,190-377,297\n",
      "4      1187982/Seri3    30217929806  BB      5  209,175-238,201\n",
      "...              ...            ...  ..    ...              ...\n",
      "17223    26361/Seri7    28750280198  BB      4  171,216-189,231\n",
      "17224    26361/Seri7    28750280200  BB      4  170,215-189,232\n",
      "17225    26361/Seri7    28750280201  BB      4  171,215-188,232\n",
      "17226    26361/Seri7    28750280201  BB      4  252,316-261,324\n",
      "17227    26361/Seri7    28750280202  BB      4  170,215-188,232\n",
      "\n",
      "[17228 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# combine results and write to a file\n",
    "res_numbers_array = [0, 0, 0, 0, 0, 0, 0]\n",
    "result_string = \"\"\n",
    "res_data_list = []\n",
    "for patient in images_dict:\n",
    "    for series in images_dict[patient]:\n",
    "        for img in images_dict[patient][series]:\n",
    "            for key in results_dict:\n",
    "                result=None\n",
    "                if results_dict[key].get(patient) != None:\n",
    "                    if results_dict[key][patient].get(series) != None:\n",
    "                        result = results_dict[key][patient][series].get(img)\n",
    "                if result != None:\n",
    "                    for res in result:\n",
    "                        res_numbers_array[key] += 1\n",
    "                        #                  olgu_num, kesit_num,       cls,             (x0,y0),             (x1,y1)\n",
    "                        res_data_list.append({\"Olgu Numarası\": f\"{patient}/{series}\", \"Kesit Numarası\": img, \"Tip\": \"BB\", \"Sınıf\": key, \"Veri\": f\"{res[0]},{res[1]}-{res[2]},{res[3]}\"})\n",
    "                        result_string += f\"{patient}/{series}, {img}, {key}, ({res[0]},{res[1]})-({res[2]},{res[3]})\\n\"\n",
    "\n",
    "with open(results_save_path, \"w\") as file:\n",
    "    file.write(result_string)\n",
    "res_data_frame = pd.DataFrame.from_records(res_data_list)\n",
    "print(res_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 568, 1944, 4105, 3810, 2142, 4659]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_numbers_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_res = results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_res = results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_1_res' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store test_1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.io.formats.excel.ExcelFormatter.header_style = None\n",
    "res_data_frame.to_excel(excel_save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f426f2e07de0045617bceb7b8a57fffa77756c699a9e132fda2811f91e926193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
